{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Group: Amy Edwards, William Chirciu\n",
    "# CSC 575 - Online 801\n",
    "# March 17,2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wchir\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# import the packages needed\n",
    "import re, math, string\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import nltk,csv\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize, sent_tokenize\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "read_in_csim = 0    # 1 if want to read in saved cosine similarities w/o rerunning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  read in the training and testing data from Kaggle\n",
    "train = pd.read_csv('train_new.csv', delimiter = '\\t', header = 0)\n",
    "test = pd.read_csv('test_new.csv', delimiter = '\\t', header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Document Indexes     (DocId -> raw term frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title_doc_index = pd.read_csv('title_doc_index_revised.csv', delimiter = '\\t', header = None, names = [\"product_uid\",\"raw_tf\"])\n",
    "description_doc_index = pd.read_csv('description_doc_index_revised.csv', delimiter = '\\t', header = None, names = [\"product_uid\",\"raw_tf\"])\n",
    "attribute_doc_index = pd.read_csv('attribute_doc_index_revised.csv',delimiter = '\\t', header = None, names = ['product_uid',\"raw_tf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_dl = {}\n",
    "desc_dl = {}\n",
    "att_dl = {}\n",
    "for index, row in title_doc_index.iterrows():\n",
    "    pId = row['product_uid']\n",
    "    title_dl[pId] = row['raw_tf']\n",
    "for index, row in description_doc_index.iterrows():\n",
    "    pId = row['product_uid']\n",
    "    desc_dl[pId] = row['raw_tf']\n",
    "for index, row in attribute_doc_index.iterrows():\n",
    "    pId = row['product_uid']\n",
    "    att_dl[pId] = row['raw_tf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Document tfxidf Vector Lengths       (DocID -> tfxIDF vector lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tfidf = pd.read_csv('title_tfidf_revised.csv', delimiter = '\\t', header = None, names = [\"product_uid\",\"tfxidf\"])\n",
    "description_tfidf = pd.read_csv('description_tfidf_revised.csv', delimiter = '\\t', header = None, names = [\"product_uid\",\"tfxidf\"])\n",
    "attribute_tfidf = pd.read_csv('attribute_tfidf_revised.csv',delimiter = '\\t', header=None, names = [\"product_uid\",\"tfxidf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_tfidf = {}                              # Title Documents tfxidf vector lengths\n",
    "D_tfidf = {}                              # Description Documents tfxidf vector lengths\n",
    "A_tfidf = {}                              # Attribute Documents tfxidf vector lengths\n",
    "for index, row in title_tfidf.iterrows():\n",
    "    pId = row['product_uid']\n",
    "    T_tfidf[pId] = row['tfxidf']\n",
    "for index, row in description_tfidf.iterrows():\n",
    "    pId = row['product_uid']\n",
    "    D_tfidf[pId] = row['tfxidf']\n",
    "for index, row in attribute_tfidf.iterrows():\n",
    "    pId = row['product_uid']\n",
    "    A_tfidf[pId] = row['tfxidf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Inverted Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "invindex_title = pd.read_csv('product_title_inverted_index_revised.csv', delimiter = '\\t', header = None, names = ['Term','IDF','Postings'])\n",
    "invindex_desc = pd.read_csv('product_description_inverted_index_revised.csv', delimiter = '\\t', header = None, names = ['Term','IDF','Postings'])\n",
    "invindex_att = pd.read_csv('product_attribute_inverted_index_revised.csv', delimiter = '\\t', header = None, names = ['Term','IDF','Postings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_invindex = {}                                   #Title Documents Inverted Index\n",
    "for index,row in invindex_title.iterrows():\n",
    "    term = row['Term']\n",
    "    idf = row['IDF']\n",
    "    T_invindex[term] = (idf,{})\n",
    "    postings = row['Postings']\n",
    "    postings = postings.strip('{')\n",
    "    postings = postings.strip('}')\n",
    "    postings = postings.split(',')\n",
    "    for i in postings:\n",
    "        string = i.strip()\n",
    "        post = string.split(': ')\n",
    "        post[0] = int(post[0])\n",
    "        post[1] = int(post[1])\n",
    "        T_invindex[term][1][post[0]] = post[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_invindex = {}                                    # Description Documents Inverted Index\n",
    "for index,row in invindex_desc.iterrows():\n",
    "    term = row['Term']\n",
    "    idf = row['IDF']\n",
    "    D_invindex[term] = (idf,{})\n",
    "    postings = row['Postings']\n",
    "    postings = postings.strip('{')\n",
    "    postings = postings.strip('}')\n",
    "    postings = postings.strip()\n",
    "    postings = postings.split(',')\n",
    "    for i in postings:\n",
    "        post = i.split(': ')\n",
    "        post[0] = int(post[0])\n",
    "        post[1] = int(post[1])\n",
    "        D_invindex[term][1][post[0]] = post[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_invindex = {}                                   # Attribute Documents Inverted Index\n",
    "for index,row in invindex_att.iterrows():\n",
    "    term = row['Term']\n",
    "    idf = row['IDF']\n",
    "    A_invindex[term] = (idf,{})\n",
    "    postings = row['Postings']\n",
    "    postings = postings.strip('{')\n",
    "    postings = postings.strip('}')\n",
    "    postings = postings.strip()\n",
    "    postings = postings.split(',')\n",
    "    for i in postings:\n",
    "        post = i.split(': ')\n",
    "        post[0] = int(post[0])\n",
    "        post[1] = int(post[1])\n",
    "        A_invindex[term][1][post[0]] = post[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit to: S. Li, “str_stem,” GitHubGist, Oct-2018. [Online]. Available: https://gist.github.com/susanli2016/b83d148de7394821509bd5172d2c96d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.PorterStemmer()\n",
    "def str_stem(s): \n",
    "    if isinstance(s, str):\n",
    "        s = re.sub(r\"([0-9])( *)\\.( *)([0-9])\", r\"\\1.\\4\", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(inches|inch|in|')\\.?\", r\"\\1in. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(foot|feet|ft|'')\\.?\", r\"\\1ft. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(pounds|pound|lbs|lb)\\.?\", r\"\\1lb. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(square|sq) ?\\.?(feet|foot|ft)\\.?\", r\"\\1sq.ft. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(cubic|cu) ?\\.?(feet|foot|ft)\\.?\", r\"\\1cu.ft. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(gallons|gallon|gal)\\.?\", r\"\\1gal. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(ounces|ounce|oz)\\.?\", r\"\\1oz. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(centimeters|cm)\\.?\", r\"\\1cm. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(milimeters|mm)\\.?\", r\"\\1mm. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(°|degrees|degree)\\.?\", r\"\\1 deg. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(v|volts|volt)\\.?\", r\"\\1 volt. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(wattage|watts|watt)\\.?\", r\"\\1 watt. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(amperes|ampere|amps|amp)\\.?\", r\"\\1 amp. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(qquart|quart)\\.?\", r\"\\1 qt. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(hours|hour|hrs.)\\.?\", r\"\\1 hr \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(gallons per minute|gallon per minute|gal per minute|gallons/min.|gallons/min)\\.?\", r\"\\1 gal. per min. \", s)\n",
    "        s = re.sub(r\"([0-9]+)( *)(gallons per hour|gallon per hour|gal per hour|gallons/hour|gallons/hr)\\.?\", r\"\\1 gal. per hr \", s)\n",
    "        # Deal with special characters\n",
    "        s = s.replace(\"$\",\" \")\n",
    "        s = s.replace(\"?\",\" \")\n",
    "        s = s.replace(\"...\",\" \")\n",
    "        s = s.replace(\"..\",\" \")\n",
    "        s = s.replace(\"&nbsp;\",\" \")\n",
    "        s = s.replace(\"&amp;\",\"&\")\n",
    "        s = s.replace(\"&#39;\",\"'\")\n",
    "        s = s.replace(\"/>/Agt/>\",\"\")\n",
    "        s = s.replace(\"</a<gt/\",\"\")\n",
    "        s = s.replace(\"gt/>\",\"\")\n",
    "        s = s.replace(\"/>\",\"\")\n",
    "        s = s.replace(\"<br\",\"\")\n",
    "        s = s.replace(\"<.+?>\",\"\")\n",
    "        s = s.replace(\"[ &<>)(_,;:!?\\+^~@#\\$]+\",\" \")\n",
    "        s = s.replace(\"'s\\\\b\",\"\")\n",
    "        s = s.replace(\"[']+\",\"\")\n",
    "        s = s.replace(\"[\\\"]+\",\"\")\n",
    "        s = s.replace(\"-\",\" \")\n",
    "        s = s.replace(\"+\",\" \")\n",
    "        # Remove text between paranthesis/brackets)\n",
    "        s = s.replace(\"[ ]?[[(].+?[])]\",\"\")\n",
    "        # remove sizes\n",
    "        s = s.replace(\"size: .+$\",\"\")\n",
    "        s = s.replace(\"size [0-9]+[.]?[0-9]+\\\\b\",\"\")\n",
    "        \n",
    "        \n",
    "        return \" \".join([stemmer.stem(re.sub('[^A-Za-z0-9-./]', ' ', word)) for word in s.lower().split()])\n",
    "    else:\n",
    "        return \"null\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that tokenizes a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize (str1) :\n",
    "    str1 = str_stem(str1)\n",
    "    tokens = word_tokenize(str1)\n",
    "    tokens = [w for w in tokens if w not in stopwords.words('english')]\n",
    "    tokens = [w for w in tokens if w != '.' and w != '/']\n",
    "    return tokens  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that returns a set of synonyms,hypernyms, and hyponyms for a given term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonyms (str1):\n",
    "    vocab = []\n",
    "\n",
    "    for syn in wordnet.synsets(str1):\n",
    "        for l in syn.lemmas():\n",
    "            line = l.name().split('_')\n",
    "            for i in line:\n",
    "                vocab.append(i)\n",
    "        for hyper in syn.hypernyms():\n",
    "            line = hyper.name().split('_')\n",
    "            for i in line:\n",
    "                vocab.append(i)\n",
    "        for hypo in syn.hyponyms():\n",
    "            line = hypo.name().split('_')\n",
    "            for i in line:\n",
    "                vocab.append(i)\n",
    "    vocab = list(set(vocab))\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Title Cosine Similarities on Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_list_title = []                    #List of cosine similarities for title documents on train data\n",
    "porter = nltk.PorterStemmer()\n",
    "\n",
    "#Cosine Similarities between Query and Product Titles for Train Data\n",
    "for index, row in train.iterrows():\n",
    "    weights = []                        # weights of all terms in the query\n",
    "    word_set = []                       # List of lists. Lists contain related words for query terms\n",
    "    score = 0.0\n",
    "    query = row['search_term']\n",
    "    doc = row['product_uid']\n",
    "    # here we split the query, and create a list of related words for each term. Append to word_set\n",
    "    for word in query.split():\n",
    "        syns = synonyms(word)\n",
    "        if not syns:\n",
    "            word_set.append([word])\n",
    "        else:\n",
    "            word_set.append([word] + syns)\n",
    "            \n",
    "    # Here we are eseentially scoring based on each word in the synset. Checking the title for all related words\n",
    "    for words in word_set:\n",
    "        toks = []\n",
    "        # for each word in the synset\n",
    "        for word in words:\n",
    "            if word in stopwords.words('english'):\n",
    "                continue\n",
    "            tokens = tokenize(word)\n",
    "            if not tokens or tokens[0] not in T_invindex:\n",
    "                continue\n",
    "            elif tokens[0] in T_invindex:\n",
    "                if doc in T_invindex[tokens[0]][1]:\n",
    "                    toks.append(tokens[0])\n",
    "        if not toks:\n",
    "            continue\n",
    "        for t in toks:\n",
    "            P = T_invindex[t][1]          # postings of term\n",
    "            I = T_invindex[t][0]          # idf of term\n",
    "            K = query.count(words[0])           # tf of term in query\n",
    "            W = K * I                       # weight of the term in the query\n",
    "            weights.append(W)\n",
    "            C = P[doc]                # tf of term in document\n",
    "            score = score + W *C*I\n",
    "    \n",
    "    if not weights:\n",
    "        cs_list_title.append(0)\n",
    "        continue\n",
    "    L = math.sqrt(sum(i*i for i in weights))   # length of query vector\n",
    "    S = score\n",
    "    Y = T_tfidf[doc]\n",
    "    if Y == 0:\n",
    "        cs_list_title.append(0)\n",
    "        continue\n",
    "    cs_list_title.append(S / (L * Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Title Cosine Similarities on Prediction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_list_title_test = []                                  #List of cosine similarities for title documents on test data\n",
    "porter = nltk.PorterStemmer()\n",
    "\n",
    "#Cosine Similarities between Query and Product Titles for Train Data\n",
    "for index, row in test.iterrows():\n",
    "    weights = []                        # weights of all terms in the query\n",
    "    word_set = []\n",
    "    score = 0.0\n",
    "    query = row['search_term']\n",
    "    doc = row['product_uid']\n",
    "    for word in query.split():\n",
    "        syns = synonyms(word)\n",
    "        if not syns:\n",
    "            word_set.append([word])\n",
    "        else:\n",
    "            word_set.append([word] + syns)\n",
    "    for words in word_set:\n",
    "        toks = []\n",
    "        # for each word in the synset\n",
    "        for word in words:\n",
    "            if word in stopwords.words('english'):\n",
    "                continue\n",
    "            tokens = tokenize(word)\n",
    "            if not tokens or tokens[0] not in T_invindex:\n",
    "                continue\n",
    "            elif tokens[0] in T_invindex:\n",
    "                if doc in T_invindex[tokens[0]][1]:\n",
    "                    toks.append(tokens[0])\n",
    "        if not toks:\n",
    "            continue\n",
    "        for t in toks:\n",
    "            P = T_invindex[t][1]          # postings of term\n",
    "            I = T_invindex[t][0]          # idf of term\n",
    "            K = query.count(words[0])           # tf of term in query\n",
    "            W = K * I                       # weight of the term in the query\n",
    "            weights.append(W)\n",
    "            C = P[doc]                # tf of term in document\n",
    "            score = score + W *C*I\n",
    "    \n",
    "    if not weights:\n",
    "        cs_list_title_test.append(0)\n",
    "        continue\n",
    "    L = math.sqrt(sum(i*i for i in weights))   # length of query vector\n",
    "    S = score\n",
    "    Y = T_tfidf[doc]\n",
    "    if Y == 0:\n",
    "        cs_list_title_test.append(0)\n",
    "        continue\n",
    "    cs_list_title_test.append(S / (L * Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Description Cosine Similarities on Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_list_description = []                              #List of cosine similarities for description documents on train data\n",
    "porter = nltk.PorterStemmer()\n",
    "\n",
    "#Cosine Similarities between Query and Product Titles for Train Data\n",
    "for index, row in train.iterrows():\n",
    "    weights = []                        # weights of all terms in the query\n",
    "    word_set = []\n",
    "    score = 0.0\n",
    "    query = row['search_term']\n",
    "    doc = row['product_uid']\n",
    "    for word in query.split():\n",
    "        syns = synonyms(word)\n",
    "        if not syns:\n",
    "            word_set.append([word])\n",
    "        else:\n",
    "            word_set.append([word] + syns)\n",
    "    for words in word_set:\n",
    "        tok = \"\"\n",
    "        # for each word in the synset\n",
    "        for word in words:\n",
    "            if word in stopwords.words('english'):\n",
    "                continue\n",
    "            tokens = tokenize(word)\n",
    "            if not tokens or tokens[0] not in D_invindex:\n",
    "                continue\n",
    "            elif tokens[0] in D_invindex:\n",
    "                if doc in D_invindex[tokens[0]][1]:\n",
    "                    tok = tokenize(word)[0]\n",
    "                    break\n",
    "        if tok == \"\":\n",
    "            continue\n",
    "        P = D_invindex[tok][1]          # postings of term\n",
    "        I = D_invindex[tok][0]          # idf of term\n",
    "        K = query.count(words[0])           # tf of term in querya\n",
    "        W = K * I                       # weight of the term in the query\n",
    "        weights.append(W)\n",
    "        C = P[doc]                # tf of term in document\n",
    "        score = score + W *C*I\n",
    "    \n",
    "    if not weights:\n",
    "        cs_list_description.append(0)\n",
    "        continue\n",
    "    L = math.sqrt(sum(i*i for i in weights))   # length of query vector\n",
    "    S = score\n",
    "    Y = T_tfidf[doc]\n",
    "    if Y == 0:\n",
    "        cs_list_description.append(0)\n",
    "        continue\n",
    "    cs_list_description.append(S / (L * Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Description Cosine Similarities on Prediction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_list_description_test = []                       #List of cosine similarities for description documents on test data\n",
    "porter = nltk.PorterStemmer()\n",
    "\n",
    "#Cosine Similarities between Query and Product Titles for Train Data\n",
    "for index, row in test.iterrows():\n",
    "    weights = []                        # weights of all terms in the query\n",
    "    word_set = []\n",
    "    score = 0.0\n",
    "    query = row['search_term']\n",
    "    doc = row['product_uid']\n",
    "    for word in query.split():\n",
    "        syns = synonyms(word)\n",
    "        if not syns:\n",
    "            word_set.append([word])\n",
    "        else:\n",
    "            word_set.append([word] + syns)\n",
    "    for words in word_set:\n",
    "        tok = \"\"\n",
    "        # for each word in the synset\n",
    "        for word in words:\n",
    "            if word in stopwords.words('english'):\n",
    "                continue\n",
    "            tokens = tokenize(word)\n",
    "            if not tokens or tokens[0] not in D_invindex:\n",
    "                continue\n",
    "            elif tokens[0] in D_invindex:\n",
    "                if doc in D_invindex[tokens[0]][1]:\n",
    "                    tok = tokenize(word)[0]\n",
    "                    break\n",
    "        if tok == \"\":\n",
    "            continue\n",
    "        P = D_invindex[tok][1]          # postings of term\n",
    "        I = D_invindex[tok][0]          # idf of term\n",
    "        K = query.count(words[0])           # tf of term in querya\n",
    "        W = K * I                       # weight of the term in the query\n",
    "        weights.append(W)\n",
    "        C = P[doc]                # tf of term in document\n",
    "        score = score + W *C*I\n",
    "    \n",
    "    if not weights:\n",
    "        cs_list_description_test.append(0)\n",
    "        continue\n",
    "    L = math.sqrt(sum(i*i for i in weights))   # length of query vector\n",
    "    S = score\n",
    "    Y = T_tfidf[doc]\n",
    "    if Y == 0:\n",
    "        cs_list_description_test.append(0)\n",
    "        continue\n",
    "    cs_list_description_test.append(S / (L * Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Attribute Cosine Similarities on Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_list_attribute = []                                    #List of cosine similarities for attribute documents on train data\n",
    "porter = nltk.PorterStemmer()\n",
    "\n",
    "#Cosine Similarities between Query and Product Titles for Train Data\n",
    "for index, row in train.iterrows():\n",
    "    weights = []                        # weights of all terms in the query\n",
    "    word_set = []\n",
    "    score = 0.0\n",
    "    query = row['search_term']\n",
    "    doc = row['product_uid']\n",
    "    for word in query.split():\n",
    "        syns = synonyms(word)\n",
    "        if not syns:\n",
    "            word_set.append([word])\n",
    "        else:\n",
    "            word_set.append([word] + syns)\n",
    "    for words in word_set:\n",
    "        tok = \"\"\n",
    "        # for each word in the synset\n",
    "        for word in words:\n",
    "            if word in stopwords.words('english'):\n",
    "                continue\n",
    "            tokens = tokenize(word)\n",
    "            if not tokens or tokens[0] not in D_invindex:\n",
    "                continue\n",
    "            elif tokens[0] in A_invindex:\n",
    "                if doc in A_invindex[tokens[0]][1]:\n",
    "                    tok = tokenize(word)[0]\n",
    "                    break\n",
    "        if tok == \"\":\n",
    "            continue\n",
    "        P = A_invindex[tok][1]          # postings of term\n",
    "        I = A_invindex[tok][0]          # idf of term\n",
    "        K = query.count(words[0])           # tf of term in querya\n",
    "        W = K * I                       # weight of the term in the query\n",
    "        weights.append(W)\n",
    "        C = P[doc]                # tf of term in document\n",
    "        score = score + W *C*I\n",
    "    \n",
    "    if not weights:\n",
    "        cs_list_attribute.append(0)\n",
    "        continue\n",
    "    L = math.sqrt(sum(i*i for i in weights))   # length of query vector\n",
    "    S = score\n",
    "    Y = T_tfidf[doc]\n",
    "    if Y == 0:\n",
    "        cs_list_attribute.append(0)\n",
    "        continue\n",
    "    cs_list_attribute.append(S / (L * Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Attribute Cosine Similarities on Prediction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_list_attribute_test = []                         #List of cosine similarities for attribute documents on test data\n",
    "porter = nltk.PorterStemmer()\n",
    "\n",
    "#Cosine Similarities between Query and Product Titles for Train Data\n",
    "for index, row in test.iterrows():\n",
    "    weights = []                        # weights of all terms in the query\n",
    "    word_set = []\n",
    "    score = 0.0\n",
    "    query = row['search_term']\n",
    "    doc = row['product_uid']\n",
    "    for word in query.split():\n",
    "        syns = synonyms(word)\n",
    "        if not syns:\n",
    "            word_set.append([word])\n",
    "        else:\n",
    "            word_set.append([word] + syns)\n",
    "    for words in word_set:\n",
    "        tok = \"\"\n",
    "        # for each word in the synset\n",
    "        for word in words:\n",
    "            if word in stopwords.words('english'):\n",
    "                continue\n",
    "            tokens = tokenize(word)\n",
    "            if not tokens or tokens[0] not in D_invindex:\n",
    "                continue\n",
    "            elif tokens[0] in A_invindex:\n",
    "                if doc in A_invindex[tokens[0]][1]:\n",
    "                    tok = tokenize(word)[0]\n",
    "                    break\n",
    "        if tok == \"\":\n",
    "            continue\n",
    "        P = A_invindex[tok][1]          # postings of term\n",
    "        I = A_invindex[tok][0]          # idf of term\n",
    "        K = query.count(words[0])           # tf of term in querya\n",
    "        W = K * I                       # weight of the term in the query\n",
    "        weights.append(W)\n",
    "        C = P[doc]                # tf of term in document\n",
    "        score = score + W *C*I\n",
    "    \n",
    "    if not weights:\n",
    "        cs_list_attribute_test.append(0)\n",
    "        continue\n",
    "    L = math.sqrt(sum(i*i for i in weights))   # length of query vector\n",
    "    S = score\n",
    "    Y = T_tfidf[doc]\n",
    "    if Y == 0:\n",
    "        cs_list_attribute_test.append(0)\n",
    "        continue\n",
    "    cs_list_attribute_test.append(S / (L * Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Cosine Similarities to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the similarities to csv, so that the entire code doesn't have to be run every time. These take a long time to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cs_list_title.csv', 'w') as csv_file:\n",
    "    csvwriter = csv.writer(csv_file, delimiter='\\t')\n",
    "    for s in cs_list_title:\n",
    "        csvwriter.writerow([s])\n",
    "with open('cs_list_title_test.csv', 'w') as csv_file:\n",
    "    csvwriter = csv.writer(csv_file, delimiter='\\t')\n",
    "    for s in cs_list_title_test:\n",
    "        csvwriter.writerow([s])\n",
    "        \n",
    "with open('cs_list_description.csv', 'w') as csv_file:\n",
    "    csvwriter = csv.writer(csv_file, delimiter='\\t')\n",
    "    for s in cs_list_description:\n",
    "        csvwriter.writerow([s])\n",
    "with open('cs_list_description_test.csv', 'w') as csv_file:\n",
    "    csvwriter = csv.writer(csv_file, delimiter='\\t')\n",
    "    for s in cs_list_description_test:\n",
    "        csvwriter.writerow([s])\n",
    "        \n",
    "with open('cs_list_attribute.csv', 'w') as csv_file:\n",
    "    csvwriter = csv.writer(csv_file, delimiter='\\t')\n",
    "    for s in cs_list_attribute:\n",
    "        csvwriter.writerow([s])\n",
    "with open('cs_list_attribute_test.csv', 'w') as csv_file:\n",
    "    csvwriter = csv.writer(csv_file, delimiter='\\t')\n",
    "    for s in cs_list_attribute_test:\n",
    "        csvwriter.writerow([s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### This reads in cosine similarities from the csv file. Useful if we need cosine similarities without having to run the algorithms again.\n",
    "if read_in_csim == 1:\n",
    "    cs_list_title = []\n",
    "    cs_list_title_test = []\n",
    "    cs_list_description = []\n",
    "    cs_list_description_test = []\n",
    "    cs_list_attribute = []\n",
    "    cs_list_attribute_test = []\n",
    "\n",
    "    df1 = pd.read_csv('cs_list_title.csv', delimiter = '\\t', header = None, names = ['sim'])\n",
    "    df2 = pd.read_csv('cs_list_title_test.csv', delimiter = '\\t', header = None, names = ['sim'])\n",
    "    df3 = pd.read_csv('cs_list_description.csv', delimiter = '\\t', header = None, names = ['sim'])\n",
    "    df4 = pd.read_csv('cs_list_description_test.csv', delimiter = '\\t', header = None, names = ['sim'])\n",
    "    df5 = pd.read_csv('cs_list_attribute.csv', delimiter = '\\t', header = None, names = ['sim'])\n",
    "    df6 = pd.read_csv('cs_list_attribute_test.csv', delimiter = '\\t', header = None, names = ['sim'])\n",
    "    \n",
    "    for index, row in df1.iterrows():\n",
    "        cs_list_title.append(row['sim'])\n",
    "    for index, row in df2.iterrows():\n",
    "        cs_list_title_test.append(row['sim'])\n",
    "    for index, row in df3.iterrows():\n",
    "        cs_list_description.append(row['sim'])\n",
    "    for index, row in df4.iterrows():\n",
    "        cs_list_description_test.append(row['sim'])\n",
    "    for index, row in df5.iterrows():\n",
    "        cs_list_attribute.append(row['sim'])\n",
    "    for index, row in df6.iterrows():\n",
    "        cs_list_attribute_test.append(row['sim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#covert the cosine csv lists to pandas dataframes\n",
    "df1 = pd.DataFrame(cs_list_title)\n",
    "df2 = pd.DataFrame(cs_list_title_test)\n",
    "df3 = pd.DataFrame(cs_list_description)\n",
    "df4 = pd.DataFrame(cs_list_description_test)\n",
    "df5 = pd.DataFrame(cs_list_attribute)\n",
    "df6 = pd.DataFrame(cs_list_attribute_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the cosine lists for training data and set names for the columns\n",
    "new_train = pd.concat([train, df1], ignore_index = True, axis = 1)\n",
    "new_train = pd.concat([new_train, df3], ignore_index = True, axis = 1)\n",
    "new_train = pd.concat([new_train, df5], ignore_index = True, axis = 1)\n",
    "new_train.columns = ['id','product_uid','product_title','search_term','relevance','cosine_title','cosine_description','cosine_attribute']\n",
    "\n",
    "#combine the cosine lists for test data and set names for the columns\n",
    "new_test = pd.concat([test, df2], ignore_index = True, axis = 1)\n",
    "new_test = pd.concat([new_test, df4], ignore_index = True, axis = 1)\n",
    "new_test = pd.concat([new_test, df6], ignore_index = True, axis = 1)\n",
    "new_test.columns = ['id','product_uid','product_title','search_term','cosine_title','cosine_description','cosine_attribute']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Length Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the descriptions file\n",
    "descriptions = pd.read_csv('product_descriptions_new.csv', delimiter = '\\t', header = 0,quoting=csv.QUOTE_NONE, error_bad_lines=False)\n",
    "descriptions.columns = ['product_uid','product_description']\n",
    "\n",
    "#merge the two pandas datasets on the product uid. \n",
    "#Left merge because if there is not a description, we still want to keep the product\n",
    "new_train = new_train.merge(descriptions, on = 'product_uid', how = 'left')\n",
    "new_test = new_test.merge(descriptions, on = 'product_uid', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the terms of query, title, description for the train and test data\n",
    "query_trm_ct = []\n",
    "for i in range(len(new_train)):\n",
    "    string = new_train['search_term'][i]\n",
    "    count = len(re.findall(\"[a-zA-Z_]+\", string))\n",
    "    query_trm_ct.append(count)\n",
    "    \n",
    "query_trm_ct_test = []\n",
    "for i in range(len(new_test)):\n",
    "    string = new_test['search_term'][i]\n",
    "    count = len(re.findall(\"[a-zA-Z_]+\", string))\n",
    "    query_trm_ct_test.append(count)\n",
    "    \n",
    "title_trm_ct = []\n",
    "for i in range(len(new_train)):\n",
    "    string = new_train['product_title'][i]\n",
    "    count = len(re.findall(\"[a-zA-Z_]+\", string))\n",
    "    title_trm_ct.append(count)\n",
    "    \n",
    "title_trm_ct_test = []\n",
    "for i in range(len(new_test)):\n",
    "    string = new_test['product_title'][i]\n",
    "    count = len(re.findall(\"[a-zA-Z_]+\", string))\n",
    "    title_trm_ct_test.append(count)\n",
    "    \n",
    "description_trm_ct = []\n",
    "for i in range(len(new_train)):\n",
    "    string = new_train['product_description'][i]\n",
    "    count = len(re.findall(\"[a-zA-Z_]+\", string))\n",
    "    description_trm_ct.append(count)\n",
    "    \n",
    "description_trm_ct_test = []\n",
    "for i in range(len(new_test)):\n",
    "    string = new_test['product_description'][i]\n",
    "    count = len(re.findall(\"[a-zA-Z_]+\", string))\n",
    "    description_trm_ct_test.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatanate the counts for query, title and description with the training and test data\n",
    "df = pd.DataFrame(query_trm_ct)\n",
    "new_train = pd.concat([new_train, df], ignore_index = True, axis = 1)\n",
    "\n",
    "df2 = pd.DataFrame(query_trm_ct_test)\n",
    "new_test = pd.concat([new_test, df2], ignore_index = True, axis = 1)\n",
    "\n",
    "df = pd.DataFrame(title_trm_ct)\n",
    "new_train = pd.concat([new_train, df], ignore_index = True, axis = 1)\n",
    "\n",
    "df2 = pd.DataFrame(title_trm_ct_test)\n",
    "new_test = pd.concat([new_test, df2], ignore_index = True, axis = 1)\n",
    "\n",
    "df = pd.DataFrame(description_trm_ct)\n",
    "new_train = pd.concat([new_train, df], ignore_index = True, axis = 1)\n",
    "\n",
    "df2 = pd.DataFrame(description_trm_ct_test)\n",
    "new_test = pd.concat([new_test, df2], ignore_index = True, axis = 1)\n",
    "\n",
    "#rename columns\n",
    "new_train.columns = ['id','product_uid','product_title','search_term','relevance','cosine_title','cosine_description','cosine_attribute','product_description','query_ct','title_ct','desc_ct']\n",
    "new_test.columns = ['id','product_uid','product_title','search_term','cosine_title','cosine_description','cosine_attribute','product_description','query_ct','title_ct','desc_ct']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creates list of binary values. 1 if entire query appears exactly as is in either Description or Title, 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_word(s, w):\n",
    "    return f' {w} ' in f' {s} '\n",
    "\n",
    "true_list = []\n",
    "for index, row in new_train.iterrows():\n",
    "    query = row['search_term']\n",
    "    description = row['product_description']\n",
    "    title = row['product_title']\n",
    "    if contains_word(description, query) != 0 or contains_word(title, query) != 0:\n",
    "        true_list.append(1)\n",
    "    else:\n",
    "        true_list.append(0)\n",
    "        \n",
    "        \n",
    "true_list_test = []\n",
    "for index, row in new_test.iterrows():\n",
    "    query = row['search_term']\n",
    "    description = row['product_description']\n",
    "    title = row['product_title']\n",
    "    if contains_word(description, query) != 0 or contains_word(title, query) != 0:\n",
    "        true_list_test.append(1)\n",
    "    else:\n",
    "        true_list_test.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Ratio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title length / query length\n",
    "title_query_ratio_train = []\n",
    "title_query_ratio_test = []\n",
    "\n",
    "for index, row in new_train.iterrows():\n",
    "    title = row['product_title']\n",
    "    query = row['search_term']\n",
    "    tcnt = len(tokenize(title))\n",
    "    qcnt = len(tokenize(query))\n",
    "    if qcnt == 0:\n",
    "        title_query_ratio_train.append(0)\n",
    "        continue\n",
    "    title_query_ratio_train.append(tcnt/qcnt)\n",
    "    \n",
    "for index, row in new_test.iterrows():\n",
    "    title = row['product_title']\n",
    "    query = row['search_term']\n",
    "    tcnt = len(tokenize(title))\n",
    "    qcnt = len(tokenize(query))\n",
    "    if qcnt == 0:\n",
    "        title_query_ratio_test.append(0)\n",
    "        continue\n",
    "    title_query_ratio_test.append(tcnt/qcnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# description length / query length\n",
    "desc_query_ratio_train = []\n",
    "desc_query_ratio_test = []\n",
    "\n",
    "for index, row in new_train.iterrows():\n",
    "    desc = row['product_description']\n",
    "    query = row['search_term']\n",
    "    dcnt = len(tokenize(desc))\n",
    "    qcnt = len(tokenize(query))\n",
    "    if qcnt == 0:\n",
    "        desc_query_ratio_train.append(0)\n",
    "        continue\n",
    "    desc_query_ratio_train.append(dcnt/qcnt)\n",
    "    \n",
    "for index, row in new_test.iterrows():\n",
    "    desc = row['product_description']\n",
    "    query = row['search_term']\n",
    "    dcnt = len(tokenize(desc))\n",
    "    qcnt = len(tokenize(query))\n",
    "    if qcnt == 0:\n",
    "        desc_query_ratio_test.append(0)\n",
    "        continue\n",
    "    desc_query_ratio_test.append(dcnt/qcnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percantage of search term in title\n",
    "tq_common_ratio_train = []\n",
    "tq_common_ratio_test = []\n",
    "\n",
    "for index, row in new_train.iterrows():\n",
    "    cnt = 0\n",
    "    title = row['product_title']\n",
    "    query = row['search_term']\n",
    "    t_tok = tokenize(title)\n",
    "    q_tok = tokenize(query)\n",
    "    if not q_tok:\n",
    "        tq_common_ratio_train.append(0)\n",
    "        continue\n",
    "    for tok in q_tok:\n",
    "        if tok in t_tok:\n",
    "            cnt = cnt + 1\n",
    "    tq_common_ratio_train.append(cnt/len(q_tok))\n",
    "    \n",
    "for index, row in new_test.iterrows():\n",
    "    cnt = 0\n",
    "    title = row['product_title']\n",
    "    query = row['search_term']\n",
    "    t_tok = tokenize(title)\n",
    "    q_tok = tokenize(query)\n",
    "    if not q_tok:\n",
    "        tq_common_ratio_test.append(0)\n",
    "        continue\n",
    "    for tok in q_tok:\n",
    "        if tok in t_tok:\n",
    "            cnt = cnt + 1\n",
    "    tq_common_ratio_test.append(cnt/len(q_tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percantage of search term in description\n",
    "dq_common_ratio_train = []\n",
    "dq_common_ratio_test = []\n",
    "\n",
    "for index, row in new_train.iterrows():\n",
    "    cnt = 0\n",
    "    description = row['product_description']\n",
    "    query = row['search_term']\n",
    "    d_tok = tokenize(description)\n",
    "    q_tok = tokenize(query)\n",
    "    if not q_tok:\n",
    "        dq_common_ratio_train.append(0)\n",
    "        continue\n",
    "    for tok in q_tok:\n",
    "        if tok in d_tok:\n",
    "            cnt = cnt + 1\n",
    "    dq_common_ratio_train.append(cnt/len(q_tok))\n",
    "    \n",
    "for index, row in new_test.iterrows():\n",
    "    cnt = 0\n",
    "    description = row['product_description']\n",
    "    query = row['search_term']\n",
    "    d_tok = tokenize(description)\n",
    "    q_tok = tokenize(query)\n",
    "    if not q_tok:\n",
    "        dq_common_ratio_test.append(0)\n",
    "        continue\n",
    "    for tok in q_tok:\n",
    "        if tok in d_tok:\n",
    "            cnt = cnt + 1\n",
    "    dq_common_ratio_test.append(cnt/len(q_tok))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jaccard Similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition for jaccard similarity\n",
    "def get_jaccard_sim(str1, str2): \n",
    "    a = set(str1.split()) #split strings\n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b) #find the common words\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c)) \n",
    "\n",
    "#similarity for product title and query - train\n",
    "jac_list_title_train = []\n",
    "#iterate though train data\n",
    "for index, row in new_train.iterrows():\n",
    "    #toeknize the product and query\n",
    "    query = row['search_term']\n",
    "    query = tokenize(query)\n",
    "    query = ' '.join(query)\n",
    "    \n",
    "    title = row['product_title']\n",
    "    title = tokenize(title)\n",
    "    title = ' '.join(title)\n",
    "    \n",
    "    jac = get_jaccard_sim(title, query)\n",
    "    jac_list_title_train.append(jac)\n",
    "\n",
    "#similarity for product title and query - test    \n",
    "jac_list_title_test = []\n",
    "# iterate through test \n",
    "for index, row in new_test.iterrows():\n",
    "    #tokenize and call jaccard definition\n",
    "    query = row['search_term']\n",
    "    query = tokenize(query)\n",
    "    query = ' '.join(query)\n",
    "    \n",
    "    title = row['product_title']\n",
    "    title = tokenize(title)\n",
    "    title = ' '.join(title)\n",
    "    \n",
    "    jac = get_jaccard_sim(title, query)\n",
    "    jac_list_title_test.append(jac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brands\n",
    "#### Try to match Brand names in query with brand names in either title or description. If brand match : 1, else: 0\n",
    "#### Tried including as many Brand names as possible in 'brands.txt', still got very few hits when in reality there should have been alot more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "brands = pd.read_csv('brands.txt', delimiter = ',', header = None)<br>\n",
    "brand_list_train = []<br>\n",
    "for index, row in new_train.iterrows(): <br>\n",
    "\n",
    "    query = row['search_term']\n",
    "    description = row['product_description']\n",
    "    title = row['product_title']\n",
    "    for i, r in brands.iterrows():\n",
    "        b = r[0].lower()<br>\n",
    "        if contains_word(b,query) == 0:\n",
    "            continue\n",
    "        if contains_word(b, description) != 0 or contains_word(b, title) != 0:\n",
    "            brand_list_train.append(1)\n",
    "        else:\n",
    "            brand_list_train.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "brand_list_test = [] <br>\n",
    "for index, row in new_test.iterrows():\n",
    "\n",
    "    query = row['search_term']\n",
    "    description = row['product_description']\n",
    "    title = row['product_title']\n",
    "    for i, r in brands.iterrows():\n",
    "        b = r[0].lower()\n",
    "        if contains_word(b,query) == 0:\n",
    "            continue\n",
    "        if contains_word(b, description) != 0 or contains_word(b, title) != 0:\n",
    "            brand_list_train.append(1)\n",
    "        else:\n",
    "            brand_list_train.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WORD2VEC\n",
    "#### Loaded in 100-dimension word vectors from glove repository\n",
    "##### This did not work as there were too many words not in the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "glove_input_file = 'glove.6B.100d.txt'<br>\n",
    "word2vec_output_file = 'glove.6B.100d.txt.word2vec'<br>\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from gensim.models import KeyedVectors # load the Stanford GloVe model<br>\n",
    "filename = 'glove.6B.100d.txt.word2vec'<br>\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for index, row in train.iterrows():\n",
    "\n",
    "    query = row['search_term'].split()\n",
    "    for word in query:\n",
    "        vector = model[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change relevance to be the target variable and move to index 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.insert(0, 'target', new_train['relevance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "del new_train['relevance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove the catagorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del new_train[\"product_title\"]\n",
    "del new_train[\"search_term\"]\n",
    "del new_train['product_description']\n",
    "del new_train['product_uid']\n",
    "\n",
    "del new_test[\"product_title\"]\n",
    "del new_test[\"search_term\"]\n",
    "del new_test['product_description']\n",
    "del new_test['product_uid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add Jaccard and search list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add jaccard \n",
    "df = pd.DataFrame(jac_list_title_train)\n",
    "new_train = pd.concat([new_train, df], ignore_index = True, axis = 1)\n",
    "\n",
    "df2 = pd.DataFrame(jac_list_title_test)\n",
    "new_test = pd.concat([new_test, df2], ignore_index = True, axis = 1)\n",
    "\n",
    "# add search list to train\n",
    "df3 = pd.DataFrame(true_list)\n",
    "new_train = pd.concat([new_train, df], ignore_index = True, axis = 1)\n",
    "\n",
    "# add search list to test\n",
    "df4 = pd.DataFrame(true_list_test)\n",
    "new_test = pd.concat([new_test, df2], ignore_index = True, axis = 1)\n",
    "\n",
    "#rename columns\n",
    "new_train.columns = ['target', 'id', 'cosine_title','cosine_description','cosine_attribute','query_ct','title_ct','desc_ct', 'jac_title', 'exact']\n",
    "new_test.columns = ['id','cosine_title','cosine_description','cosine_attribute','query_ct','title_ct','desc_ct', 'jac_title','exact']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ratios to train and test dataframe\n",
    "df1 = pd.DataFrame(title_query_ratio_train)\n",
    "df2 = pd.DataFrame(title_query_ratio_test)\n",
    "df3 = pd.DataFrame(desc_query_ratio_train)\n",
    "df4 = pd.DataFrame(desc_query_ratio_test)\n",
    "df5 = pd.DataFrame(tq_common_ratio_train)\n",
    "df6 = pd.DataFrame(tq_common_ratio_test)\n",
    "df7 = pd.DataFrame(dq_common_ratio_train)\n",
    "df8 = pd.DataFrame(dq_common_ratio_test)\n",
    "\n",
    "new_train = pd.concat([new_train, df1], ignore_index = True, axis = 1)\n",
    "new_train = pd.concat([new_train, df3], ignore_index = True, axis = 1)\n",
    "new_train = pd.concat([new_train, df5], ignore_index = True, axis = 1)\n",
    "new_train = pd.concat([new_train, df7], ignore_index = True, axis = 1)\n",
    "\n",
    "new_test = pd.concat([new_test, df2], ignore_index = True, axis = 1)\n",
    "new_test = pd.concat([new_test, df4], ignore_index = True, axis = 1)\n",
    "new_test = pd.concat([new_test, df6], ignore_index = True, axis = 1)\n",
    "new_test = pd.concat([new_test, df8], ignore_index = True, axis = 1)\n",
    "\n",
    "#because we used concat we have to rename the columns of the dataframes\n",
    "new_train.columns = ['target', 'id', 'cosine_title','cosine_description','cosine_attribute','query_ct','title_ct','desc_ct', 'jac_title', 'exact','title_query_ratio','desc_query_ratio','tq_common_ratio','dq_common_ratio']\n",
    "new_test.columns = ['id','cosine_title','cosine_description','cosine_attribute','query_ct','title_ct','desc_ct', 'jac_title', 'exact','title_query_ratio','desc_query_ratio','tq_common_ratio','dq_common_ratio']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save cleaned files with features for regression\n",
    "new_train.to_csv(r'forRegression.csv', index=None, header = True)\n",
    "new_test.to_csv(r'forRegressionTest.csv', index=None, header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
